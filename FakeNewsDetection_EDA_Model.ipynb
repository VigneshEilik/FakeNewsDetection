{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udcd8 Fake News Detection Project - EDA + ML Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Import Libraries\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import string\n", "import nltk\n", "import pickle\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.naive_bayes import MultinomialNB\n", "nltk.download('stopwords')\n", "from nltk.corpus import stopwords\n", "from nltk.stem.porter import PorterStemmer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 2: Load Dataset\n", "df = pd.read_csv('data/fake_or_real_news.csv')\n", "df.dropna(inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 3: Exploratory Data Analysis (EDA)\n", "print(\"\\nShape of Dataset:\", df.shape)\n", "print(\"\\nData Types:\\n\", df.dtypes)\n", "print(\"\\nLabel Distribution:\\n\", df['label'].value_counts())\n", "sns.countplot(data=df, x='label')\n", "plt.title(\"Fake vs Real News Distribution\")\n", "plt.show()\n", "df['text_len'] = df['text'].apply(lambda x: len(x.split()))\n", "sns.histplot(data=df, x='text_len', hue='label', bins=50)\n", "plt.title(\"Word Count Distribution by Label\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 4: Text Preprocessing\n", "def clean_text(text):\n", "    text = text.lower()\n", "    text = ''.join([char for char in text if char not in string.punctuation])\n", "    words = text.split()\n", "    ps = PorterStemmer()\n", "    stop_words = set(stopwords.words('english'))\n", "    return ' '.join([ps.stem(word) for word in words if word not in stop_words])\n", "df['clean_text'] = df['text'].apply(clean_text)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 5: Train-Test Split\n", "X = df['clean_text']\n", "y = df['label']\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 6: TF-IDF + Logistic Regression Pipeline\n", "model = Pipeline([\n", "    ('tfidf', TfidfVectorizer()),\n", "    ('clf', LogisticRegression())\n", "])\n", "model.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 7: Evaluate the Model\n", "y_pred = model.predict(X_test)\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(\"F1 Score:\", f1_score(y_test, y_pred, pos_label='REAL'))\n", "print(confusion_matrix(y_test, y_pred))\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 8: Save the Model\n", "with open('models/fake_news_model.pkl', 'wb') as f:\n", "    pickle.dump(model, f)\n", "print(\"\\n\u2705 Model saved successfully as 'fake_news_model.pkl'\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}